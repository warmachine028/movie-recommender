{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing Necessary Pacakges for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: scikit-learn in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: nltk in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (from pandas) (1.24.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: click in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas scikit-learn nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits = pd.read_csv(\"data/tmdb_5000_credits.csv\")\n",
    "movies = pd.read_csv(\"data/tmdb_5000_movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.merge(credits, on=\"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing \n",
    "1. Feature Selection (Dimentionality Reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genres\n",
    "# id\n",
    "# keywords\n",
    "# title\n",
    "# overview\n",
    "# cast\n",
    "# crew\n",
    "\n",
    "movies = movies[[\"id\", \"title\", \"overview\", \"genres\", \"keywords\", \"cast\", \"crew\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Feature cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Checking for Duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Applying function on features to convert them to lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast # Abstract Syntax Tree\n",
    "\n",
    "\n",
    "def convert_to_list(column: str) -> list:\n",
    "    return [item['name'] for item in ast.literal_eval(column)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['genres'] = movies['genres'].apply(convert_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['keywords'] = movies['keywords'].apply(convert_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['cast'] = movies['cast'].apply(lambda casts: convert_to_list(casts)[: 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['crew'] = movies['crew'].apply(lambda crews: [crew['name'] for crew in ast.literal_eval(crews) if crew['job'] == 'Director'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['overview'] = movies['overview'].apply(lambda text: text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_words(strings: list[str]) -> list[str]:\n",
    "    return [string.replace(\" \", \"\") for string in strings]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['genres'] = movies['genres'].apply(concatenate_words)\n",
    "movies['keywords'] = movies['keywords'].apply(concatenate_words)\n",
    "movies['cast'] = movies['cast'].apply(concatenate_words)\n",
    "movies['crew'] = movies['crew'].apply(concatenate_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. New Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(movies[['id', 'title', 'tags']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                                     title  \\\n",
      "0      19995                                    Avatar   \n",
      "1        285  Pirates of the Caribbean: At World's End   \n",
      "2     206647                                   Spectre   \n",
      "3      49026                     The Dark Knight Rises   \n",
      "4      49529                               John Carter   \n",
      "...      ...                                       ...   \n",
      "4804    9367                               El Mariachi   \n",
      "4805   72766                                 Newlyweds   \n",
      "4806  231617                 Signed, Sealed, Delivered   \n",
      "4807  126186                          Shanghai Calling   \n",
      "4808   25975                         My Date with Drew   \n",
      "\n",
      "                                                   tags  \n",
      "0     [In, the, 22nd, century,, a, paraplegic, Marin...  \n",
      "1     [Captain, Barbossa,, long, believed, to, be, d...  \n",
      "2     [A, cryptic, message, from, Bondâ€™s, past, send...  \n",
      "3     [Following, the, death, of, District, Attorney...  \n",
      "4     [John, Carter, is, a, war-weary,, former, mili...  \n",
      "...                                                 ...  \n",
      "4804  [El, Mariachi, just, wants, to, play, his, gui...  \n",
      "4805  [A, newlywed, couple's, honeymoon, is, upended...  \n",
      "4806  [\"Signed,, Sealed,, Delivered\", introduces, a,...  \n",
      "4807  [When, ambitious, New, York, attorney, Sam, is...  \n",
      "4808  [Ever, since, the, second, grade, when, he, fi...  \n",
      "\n",
      "[4806 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['tags'] = new_df['tags'].apply(lambda lst: ' '.join(map(str.lower, lst)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Apply stemming on features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with stemming\n",
    "new_df['tags'] = new_df['tags'].apply(lambda tags: ' '.join(ps.stem(tag) for tag in tags.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()\n",
    "print(\n",
    "    *new_df[new_df['title']=='Final Destination']['tags']\n",
    ")\n",
    "print(\n",
    "    *new_df[new_df['title']=='Final Destination 2']['tags']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "cv = CountVectorizer(max_features=10000, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = cv.fit_transform(new_df['tags']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.get_feature_names_out()[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Calculating using cosine similarity instead of Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(movie):\n",
    "    movie_index = new_df[new_df['title'] == movie].index[0]\n",
    "    distances = similarity[movie_index]\n",
    "    movies = enumerate(distances)\n",
    "    recommended_movies = sorted(movies, reverse=True, key=lambda m: m[1])\n",
    "    top_5_recommendations = recommended_movies[1:6]\n",
    "\n",
    "    return [new_df.iloc[index].title for index, _ in top_5_recommendations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Testing on a data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend('Avatar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Exporting new Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "pickle.dump(new_df, open('movies.pkl', 'wb'))\n",
    "pickle.dump(similarity, open('similarity.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "7cc880fb414a6190fbce021e54b9550a41e00b0ed8e95a947d98634e734d910a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
