{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing Necessary Pacakges for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: scikit-learn in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: nltk in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (from pandas) (1.24.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: click in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in d:\\programs\\python\\movies-recommender\\venv\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas scikit-learn nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits = pd.read_csv(\"data/tmdb_5000_credits.csv\")\n",
    "movies = pd.read_csv(\"data/tmdb_5000_movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.merge(credits, on=\"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing \n",
    "1. Feature Selection (Dimentionality Reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genres\n",
    "# id\n",
    "# keywords\n",
    "# title\n",
    "# overview\n",
    "# cast\n",
    "# crew\n",
    "\n",
    "movies = movies[[\"id\", \"title\", \"overview\", \"genres\", \"keywords\", \"cast\", \"crew\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Feature cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Checking for Duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Applying function on features to convert them to lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast # Abstract Syntax Tree\n",
    "\n",
    "\n",
    "def convert_to_list(column: str) -> list:\n",
    "    return [item['name'] for item in ast.literal_eval(column)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['genres'] = movies['genres'].apply(convert_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['keywords'] = movies['keywords'].apply(convert_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['cast'] = movies['cast'].apply(lambda casts: convert_to_list(casts)[: 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['crew'] = movies['crew'].apply(lambda crews: [crew['name'] for crew in ast.literal_eval(crews) if crew['job'] == 'Director'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['overview'] = movies['overview'].apply(lambda text: text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_words(strings: list[str]) -> list[str]:\n",
    "    return [string.replace(\" \", \"\") for string in strings]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['genres'] = movies['genres'].apply(concatenate_words)\n",
    "movies['keywords'] = movies['keywords'].apply(concatenate_words)\n",
    "movies['cast'] = movies['cast'].apply(concatenate_words)\n",
    "movies['crew'] = movies['crew'].apply(concatenate_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. New Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(movies[['id', 'title', 'tags']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                                     title  \\\n",
      "0      19995                                    Avatar   \n",
      "1        285  Pirates of the Caribbean: At World's End   \n",
      "2     206647                                   Spectre   \n",
      "3      49026                     The Dark Knight Rises   \n",
      "4      49529                               John Carter   \n",
      "...      ...                                       ...   \n",
      "4804    9367                               El Mariachi   \n",
      "4805   72766                                 Newlyweds   \n",
      "4806  231617                 Signed, Sealed, Delivered   \n",
      "4807  126186                          Shanghai Calling   \n",
      "4808   25975                         My Date with Drew   \n",
      "\n",
      "                                                   tags  \n",
      "0     [In, the, 22nd, century,, a, paraplegic, Marin...  \n",
      "1     [Captain, Barbossa,, long, believed, to, be, d...  \n",
      "2     [A, cryptic, message, from, Bond’s, past, send...  \n",
      "3     [Following, the, death, of, District, Attorney...  \n",
      "4     [John, Carter, is, a, war-weary,, former, mili...  \n",
      "...                                                 ...  \n",
      "4804  [El, Mariachi, just, wants, to, play, his, gui...  \n",
      "4805  [A, newlywed, couple's, honeymoon, is, upended...  \n",
      "4806  [\"Signed,, Sealed,, Delivered\", introduces, a,...  \n",
      "4807  [When, ambitious, New, York, attorney, Sam, is...  \n",
      "4808  [Ever, since, the, second, grade, when, he, fi...  \n",
      "\n",
      "[4806 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['tags'] = new_df['tags'].apply(lambda lst: ' '.join(map(str.lower, lst)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Apply stemming on features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with stemming\n",
    "new_df['tags'] = new_df['tags'].apply(lambda tags: ' '.join(ps.stem(tag) for tag in tags.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after a teenag ha a terrifi vision of him and hi friend die in a plane crash, he prevent the accid onli to have death hunt them down, one by one. horror omen airplaneaccid corps death near-deathexperi devonsawa alilart kerrsmith jameswong\n",
      "when kimberli ha a violent premonit of a highway pileup she block the freeway, keep a few other meant to die, safe...or are they? the survivor mysteri start die and it' up to kimberli to stop it befor she' next. horror mysteri ambul premonit hospit alilart a.j.cook michaelland davidr.elli\n"
     ]
    }
   ],
   "source": [
    "new_df.head()\n",
    "print(\n",
    "    *new_df[new_df['title']=='Final Destination']['tags']\n",
    ")\n",
    "print(\n",
    "    *new_df[new_df['title']=='Final Destination 2']['tags']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "cv = CountVectorizer(max_features=10000, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = cv.fit_transform(new_df['tags']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '007', '10', '100', '10th', '11', '12', '12th', '13',\n",
       "       '14', '15', '150', '15th', '16', '16th', '17', '17th', '18',\n",
       "       '1863', '1890', '18th', '18thcenturi', '19', '1910', '1920',\n",
       "       '1927', '1930', '1930s', '1937', '1940', '1940s', '1941', '1944',\n",
       "       '1945', '1950', '1950s', '1955', '1959', '1960', '1960s', '1962',\n",
       "       '1964', '1965', '1967', '1969', '1970', '1970s', '1971', '1972',\n",
       "       '1973', '1974', '1976', '1977', '1979', '1980', '1980s', '1984',\n",
       "       '1985', '1986', '1987', '1990', '1994', '1995', '1996', '1997',\n",
       "       '1999', '19th', '19thcenturi', '20', '200', '2000', '2001', '2002',\n",
       "       '2003', '2004', '2007', '2008', '2009', '2011', '2012', '20th',\n",
       "       '21st', '21stcenturi', '22nd', '23', '24', '25', '27', '28', '29',\n",
       "       '30', '300', '35', '3d', '40', '400', '47', '50', '500', '51',\n",
       "       '60', '60s', '70', '7th', '80', 'aaron', 'aaroneckhart',\n",
       "       'aaronseltz', 'aarontaylor', 'abandon', 'abbi', 'abbiecornish',\n",
       "       'abduct', 'abigailbreslin', 'abil', 'abl', 'aboard',\n",
       "       'abolitionist', 'aborigin', 'abort', 'abov', 'abraham', 'abram',\n",
       "       'abroad', 'abrupt', 'abruptli', 'absenc', 'absence', 'absent',\n",
       "       'absolut', 'abstract', 'absurd', 'abus', 'abuse', 'abusivehusband',\n",
       "       'academ', 'academi', 'academy', 'accept', 'acceptance', 'accepts',\n",
       "       'access', 'accid', 'accident', 'accidental', 'acclaim', 'acclim',\n",
       "       'accompani', 'accomplish', 'account', 'accountant', 'accus',\n",
       "       'accused', 'ace', 'achiev', 'acid', 'acquaint', 'acquir', 'acr',\n",
       "       'act', 'action', 'actionhero', 'actions', 'activ', 'activist',\n",
       "       'activities', 'actor', 'actress', 'actual', 'ad', 'ada', 'adam',\n",
       "       'adambeach', 'adambrodi', 'adamcarolla', 'adamdriv', 'adamgarcia',\n",
       "       'adamgoldberg', 'adammckay', 'adams', 'adamsandl', 'adamscott',\n",
       "       'adamshankman', 'adapt', 'add', 'addict', 'addiction', 'addit',\n",
       "       'addl', 'adjust', 'admir', 'admit', 'adolesc', 'adolf',\n",
       "       'adolfhitl', 'adopt', 'adoptivefath', 'ador', 'adrian',\n",
       "       'adrianlyn', 'adrienbrodi', 'adrift', 'adult', 'adultanim',\n",
       "       'adulteri', 'adulthood', 'adults', 'advanc', 'advantag',\n",
       "       'advantage', 'adventur', 'adventure', 'adventures', 'adversari',\n",
       "       'advertis', 'advic', 'advice', 'advis', 'affair', 'affect',\n",
       "       'affection', 'afflict', 'affluent', 'afford', 'afghanistan',\n",
       "       'afraid', 'africa', 'african', 'africanamerican', 'afro',\n",
       "       'aftercreditssting', 'afterlif', 'aftermath', 'afternoon', 'ag',\n",
       "       'age', 'agediffer', 'agenc', 'agency', 'agenda', 'agent', 'agents',\n",
       "       'aggress', 'aggressionbyanim', 'ago', 'agre', 'agrees', 'ahead',\n",
       "       'aid', 'aidan', 'aidanquinn', 'ail', 'aim', 'air', 'airborn',\n",
       "       'aircraft', 'airforc', 'airplan', 'airplanecrash', 'airport',\n",
       "       'aka', 'akshaykumar', 'al', 'alabama', 'alan', 'alanalda',\n",
       "       'alanarkin', 'alanrickman', 'alaska', 'alaskan', 'albert',\n",
       "       'albertbrook', 'albertfinney', 'alcatraz', 'alcohol',\n",
       "       'alcoholabus', 'aldou', 'alec', 'alecbaldwin', 'alecguin',\n",
       "       'alejandroamenábar', 'alejandrogonzáleziñárritu', 'alex',\n",
       "       'alexanderpayn', 'alexanderskarsgård', 'alexandradaddario',\n",
       "       'alexandreaja', 'alexapenavega', 'alexia', 'alexisbledel',\n",
       "       'alexkendrick', 'alexpettyf', 'alexproya', 'alfi', 'alfonsocuarón',\n",
       "       'alfredhitchcock', 'alfredmolina', 'algeria', 'ali', 'alibi',\n",
       "       'alic', 'alice', 'alicebraga', 'aliceev', 'aliciasilverston',\n",
       "       'aliciavikand', 'aliciawitt', 'alien', 'alienabduct',\n",
       "       'alienattack', 'aliencontact', 'alieninfect', 'alieninvas',\n",
       "       'alienlife', 'alienphenomenon', 'alienplanet', 'aliens', 'alik',\n",
       "       'alike', 'alilart', 'alisonlohman', 'aliv', 'alive', 'alleg',\n",
       "       'allegedli', 'allegra', 'allen', 'allenhugh', 'alli', 'allianc',\n",
       "       'allies', 'allow', 'allur', 'alon', 'alongsid', 'alp', 'alpacino',\n",
       "       'alpha', 'alreadi', 'alt', 'alter', 'altern', 'alternatedimens',\n",
       "       'alternatehistori', 'alternater', 'alvin', 'alway',\n",
       "       'alysonhannigan', 'alyssa', 'alzheim', 'alzheimer', 'amanda',\n",
       "       'amandabyn', 'amandapeet', 'amandaseyfri', 'amateur', 'amaz',\n",
       "       'amazon', 'ambassador', 'amber', 'amberheard', 'ambertamblyn',\n",
       "       'ambit', 'ambiti', 'ambul', 'ambush', 'amelia', 'america',\n",
       "       'americaferrera', 'american', 'americanabroad', 'americancivilwar',\n",
       "       'americandream', 'americanfootbal', 'americanfootballplay', 'ami',\n",
       "       'amid', 'amidst', 'amnesia', 'amor', 'amp', 'amsterdam', 'amus',\n",
       "       'amusementpark', 'amy', 'amyadam', 'amyheckerl', 'amypoehl',\n",
       "       'amysmart', 'ana', 'anakin', 'analyst', 'anarchiccomedi',\n",
       "       'anarchist', 'ancient', 'ancientchina', 'ancientegypt',\n",
       "       'ancientgreec', 'ancientrom', 'ancientworld', 'anderson', 'andi',\n",
       "       'andiemacdowel', 'andrew', 'andrewadamson', 'andrewdavi',\n",
       "       'andrewflem', 'andrewgarfield', 'andrewniccol', 'andrewstanton',\n",
       "       'android', 'andrzejbartkowiak', 'andy', 'andyfickman',\n",
       "       'andygarcía', 'andysamberg', 'andyserki', 'andytenn', 'angel',\n",
       "       'angela', 'angelabassett', 'angeles', 'angelinajoli', 'angels',\n",
       "       'anger', 'angle', 'angri', 'angst', 'ani', 'anim', 'animal',\n",
       "       'animalattack', 'animalhorror', 'animals', 'anjelicahuston', 'ann',\n",
       "       'anna', 'annabel', 'annabellasciorra', 'annafari', 'annafriel',\n",
       "       'annakendrick', 'annasophiarobb', 'anne', 'annebancroft',\n",
       "       'annefletch', 'annehathaway', 'annehech', 'annemoss', 'annetteben',\n",
       "       'anni', 'annie', 'anniversari', 'announc', 'annoy', 'annual',\n",
       "       'anonym', 'anoth', 'answer', 'answers', 'ant', 'antarct',\n",
       "       'antarctica', 'antholog', 'anthoni', 'anthonyanderson',\n",
       "       'anthonyhopkin', 'anthonymacki', 'anthonyquinn', 'anthonyrusso',\n",
       "       'anthropomorph', 'anti', 'antic', 'anticip', 'antics', 'antihero',\n",
       "       'antiqu', 'antisemit', 'antiterror', 'antoinefuqua', 'anton',\n",
       "       'antonio', 'antoniobandera', 'antonyelchin', 'anxieti', 'anyon',\n",
       "       'anyth', 'apart', 'apartheid', 'apartment', 'ape', 'apes',\n",
       "       'apocalyps', 'apocalypse', 'apocalypt', 'apollo', 'apostl',\n",
       "       'appalachia', 'appar'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names_out()[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Calculating using cosine similarity instead of Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(movie):\n",
    "    movie_index = new_df[new_df['title'] == movie].index[0]\n",
    "    print(new_df[new_df['title'] == movie], movie_index)\n",
    "    distances = similarity[movie_index]\n",
    "    movies = enumerate(distances)\n",
    "    recommended_movies = sorted(movies, reverse=True, key=lambda m: m[1])\n",
    "    top_5_recommendations = recommended_movies[1:6]\n",
    "\n",
    "    return [new_df.iloc[index].title for index, _ in top_5_recommendations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Testing on a data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                title  \\\n",
      "1845  9286  Final Destination 3   \n",
      "\n",
      "                                                   tags  \n",
      "1845  a student' premonit of a deadli rollercoast ri...   1845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The Final Destination',\n",
       " 'Final Destination 5',\n",
       " 'Antiviral',\n",
       " 'Flatliners',\n",
       " 'Absentia']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend('Final Destination 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.19681254499043666,\n",
       " 0.20100756305184242,\n",
       " 0.20123585110162412,\n",
       " 0.22019275302527216,\n",
       " 0.22619193331698284,\n",
       " 0.24747528995589838,\n",
       " 0.2545454545454546,\n",
       " 0.27749837403772815,\n",
       " 1.0]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(similarity[1227])[-9:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Exporting new Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "pickle.dump(new_df, open('data/movies.pkl', 'wb'))\n",
    "pickle.dump(similarity, open('data/similarity.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "7cc880fb414a6190fbce021e54b9550a41e00b0ed8e95a947d98634e734d910a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
